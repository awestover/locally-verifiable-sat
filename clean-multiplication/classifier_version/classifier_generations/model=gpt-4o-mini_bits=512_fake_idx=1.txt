============================================================
METADATA
============================================================

Model: gpt-4o-mini
Bits: 512
Transcript type: fake
P: None
Q: None

ERROR: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 218196 tokens (218179 in the messages, 17 in the functions). Please reduce the length of the messages or functions.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
